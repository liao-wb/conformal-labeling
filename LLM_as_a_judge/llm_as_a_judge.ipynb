{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-03T14:30:39.415937Z",
     "start_time": "2025-08-03T14:30:38.373355Z"
    }
   },
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import json\n",
    "import os"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mjson\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'transformers'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_path = \"\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)"
   ],
   "id": "c931701d27add675"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data_file = \"LLM_as_a_judge/LLMEval2_benchmark.json\"  # ä¿®æ”¹ä¸ºä½ çš„æ•°æ®é›†è·¯å¾„\n",
    "\n",
    "with open(data_file, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "print(f\"å…±åŠ è½½ {len(dataset)} æ¡æ•°æ®\")"
   ],
   "id": "4b23b984cc7a929c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "evaluations = []\n",
    "\n",
    "for entry in dataset:\n",
    "    query = entry[\"query\"]\n",
    "    response1 = entry[\"response1\"]\n",
    "    response2 = entry[\"response2\"]\n",
    "    human_label = entry[\"human\"]\n",
    "\n",
    "    # æ„é€  prompt\n",
    "    prompt = \\\n",
    "        f\"\"\"\n",
    "        You are an expert language evaluator. Compare the following two responses to the given query and determine which one is better in terms of clarity, helpfulness, relevance, and fluency.\n",
    "\n",
    "        Query: \"{query}\"\n",
    "        Response 1: \"{response1}\"\n",
    "        Response 2: \"{response2}\"\n",
    "        \n",
    "        Which response is better? Reply with \"1\" or \"2\" and briefly explain why.\n",
    "        \"\"\"\n",
    "\n",
    "    # æ‹¼æ¥å¯¹è¯æ ¼å¼\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    # ç¼–ç è¾“å…¥\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "    # ç”Ÿæˆå“åº”ï¼Œå¼€å¯è¿”å› score\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True\n",
    "    )\n",
    "\n",
    "    # è§£ç è¾“å‡ºå†…å®¹\n",
    "    response_ids = output.sequences[0][len(inputs.input_ids[0]):].tolist()\n",
    "    response_text = tokenizer.decode(response_ids, skip_special_tokens=True)\n",
    "\n",
    "    # è®¡ç®—ä¿¡å¿ƒåº¦ï¼šsoftmax åçš„æœ€å¤§æ¦‚ç‡å‡å€¼\n",
    "    scores = output.scores\n",
    "    token_probs = torch.nn.functional.softmax(torch.cat(scores), dim=-1)\n",
    "    max_probs = torch.max(token_probs, dim=-1).values\n",
    "    confidence = max_probs.mean().item()\n",
    "\n",
    "    # åˆ¤æ–­æ¨¡å‹è¾“å‡ºçš„æ˜¯é€‰1è¿˜æ˜¯é€‰2\n",
    "    if \"1\" in response_text:\n",
    "        model_prediction = \"1\"\n",
    "    elif \"2\" in response_text:\n",
    "        model_prediction = \"2\"\n",
    "    else:\n",
    "        model_prediction = \"unknown\"\n",
    "\n",
    "    # å¯¹æ¯”æ ‡ç­¾ï¼Œç»Ÿè®¡å‡†ç¡®ç‡\n",
    "    if model_prediction == human_label:\n",
    "        correct_predictions += 1\n",
    "    total_predictions += 1\n",
    "\n",
    "    # ä¿å­˜ç»“æœ\n",
    "    evaluations.append({\n",
    "        \"query\": query,\n",
    "        \"response1\": response1,\n",
    "        \"response2\": response2,\n",
    "        \"human\": human_label,\n",
    "        \"model_output\": response_text.strip(),\n",
    "        \"model_choice\": model_prediction,\n",
    "        \"confidence\": confidence\n",
    "    })"
   ],
   "id": "b9e38db22ad46bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0.0\n",
    "print(f\"ğŸŒŸ æ¨¡å‹è¯„ä¼°å‡†ç¡®ç‡ï¼š{accuracy * 100:.2f}%\")"
   ],
   "id": "9ef65122bdcb786"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for i, eval_item in enumerate(evaluations[:5]):\n",
    "    print(f\"ğŸ“ ç¤ºä¾‹ {i+1}\")\n",
    "    print(\"é—®é¢˜:\", eval_item[\"query\"])\n",
    "    print(\"å“åº” 1:\", eval_item[\"response1\"])\n",
    "    print(\"å“åº” 2:\", eval_item[\"response2\"])\n",
    "    print(\"äººç±»æ ‡ç­¾:\", eval_item[\"human\"])\n",
    "    print(\"æ¨¡å‹è¾“å‡º:\", eval_item[\"model_output\"])\n",
    "    print(\"æ¨¡å‹é€‰æ‹©:\", eval_item[\"model_choice\"])\n",
    "    print(f\"è‡´ä¿¡åº¦: {eval_item['confidence']:.4f}\")\n",
    "    print(\"-\" * 50)"
   ],
   "id": "850a161087e1fe1e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
